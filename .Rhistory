labs(x = "Sample Type", y = "Relative Abundance", fill = "Family") +
scale_fill_manual(values = c("grey90", brewer.pal(12, "Paired")[12:1]),
labels = c("Other", fam_stats$StarLab)) +
scale_y_continuous(expand = c(0.01, 0.01)) +
facet_nested(~ Farm_type + Sample_type, space = "free", scales = "free_x") +
theme_classic() +
theme(axis.title.y = element_text(face = "bold", size = 12),
axis.title.x = element_blank(),
axis.text.y = element_text(size = 10),
axis.text.x = element_text(size = 8, angle = 90, hjust = 1, vjust = 0.5),
axis.ticks.x = element_blank(),
axis.line.x = element_blank(),
strip.text = element_text(size = 6),
strip.background = element_rect(linewidth = 0.2),
axis.line.y = element_blank(),
legend.margin = margin(0, 0, 0, 0, unit = "pt"),
legend.box.margin = margin(0, 0, 0, 0, unit = "pt"),
legend.key.size = unit(0.3, "cm"),
panel.spacing.x = unit(c(0.2, 0.2, 0.4, 0.2, 0.2), "lines"))
# Test (run a Kruskal-Wallis test on all families with mean rel abund. > filter_level in at least one of the factor levels)
taxa_summary_by_sample_type(tax_sum_families,
input_filt_rar$map_loaded,
type_header = 'Sample_type',
filter_level = 0.05,
test_type = 'KW')
# Or Wilcoxon for 2 levels (farm type)
taxa_summary_by_sample_type(tax_sum_families,
input_filt_rar$map_loaded,
type_header = 'Farm_type',
filter_level = 0.05,
test_type = 'MW')
knitr::opts_chunk$set(echo = TRUE)
# R packages required for this tutorial
suppressMessages(library(mctoolsr)) # For inputting, rarefying, filtering, taxonomic analyses
suppressMessages(library(plyr)) # For hulls
library(tidyverse)
suppressMessages(library(mctoolsr)) # For inputting, rarefying, filtering, taxonomic analyses
suppressMessages(library(plyr)) # For hulls
suppressMessages(library(tidyverse)) # For data manipulation and plotting
suppressMessages(library(RColorBrewer)) # For color palettes
suppressMessages(library(vegan)) # For alpha and beta diversity analyses
suppressMessages(library(indicspecies)) # For indicator species
suppressMessages(library(car)) # For Levene Test and ANOVA
suppressMessages(library(PMCMRplus)) # For Nemenyi posthoc test
suppressMessages(library(ggh4x)) # For nested facet plots
suppressMessages(library(emmeans)) # For pairwise comparisons
suppressMessages(library(multcomp)) # For automated significant difference letters
suppressMessages(library(zCompositions)) # CLR
suppressMessages(library(compositions)) # Aitchison
suppressMessages(library(reshape2)) # For melting
suppressMessages(library(cowplot)) # For plotting
# Note: This tutorial was run with dplyr 1.1.3. If you are using a newer version of dplyr, you may need to install and load this version using:
#install.packages("dplyr", version='1.1.3')
#library(dplyr)
# If you haven't already installed these packages before, you will need to install them with:
# install.packages()
# For Installing mctoolsR the first time, use:
# install.packages("devtools")
# devtools::install_github("leffj/mctoolsr")
# Custom functions
source("cliffplot_taxa_bars.R")
source("plot_multipatt_asv.R")
# Loading ASV Table
tax_table_fp = system.file('extdata', 'fruits_veggies_taxa_table_wTax.biom',
package = 'mctoolsr')
# Loading mapping file
map_fp = system.file('extdata', 'fruits_veggies_metadata.txt',
package = 'mctoolsr')
# Combine the ASV table and mapping file into an mctoolsR object
input = load_taxa_table(tax_table_fp, map_fp)
# Copy the dataset before doing any filtering
input_filt <- input
# This filters out any ASVs from input dataframe ("input_filt") not assigned to a phylum (at taxonomy level 2 = "NA")
input_filt <- filter_taxa_from_input(input_filt,
at_spec_level = 2,
taxa_to_remove = "unclassified") # 978
# Filtering out mitochondria sequences from the filtered input dataset.
input_filt <- filter_taxa_from_input(input_filt,
taxa_to_remove = "f__mitochondria") # 14
# Filtering out chloroplast sequences
input_filt <- filter_taxa_from_input(input_filt,
taxa_to_remove = "c__Chloroplast") # 1
# Filtering out singletons and doubletons
# First we'll save the ASV IDs of ASVs with less than 3 total counts
singdoub <- data.frame("count" = rowSums(input_filt$data_loaded)) %>%
filter(count < 3) %>%
mutate(ASV = rownames(.))
# Now we'll provide that list of ASV IDs to the taxa_IDs_to_remove argument
input_filt <- filter_taxa_from_input(input_filt,
taxa_IDs_to_remove = singdoub$ASV)
# In addition to taxonomic filtering, you can filter out samples. For example, let's filter out lettuce samples. We can give a variable name and levels of the variable to filter or keep.
input_filt <- filter_data(input_filt, # provide input_filt again. careful!
filter_cat = "Sample_type",
filter_vals = "Lettuce") # 28 samples remaining (removed 4)
# Lets save the filtered but unrarefied dataset.
saveRDS(input_filt, file = "input_filt.rds")
# You can read it in like this:
input_filt <- readRDS("input_filt.rds")
# You can read it in like this:
input_filt <- readRDS("input_filt.rds")
# Rarefying data
## Moving on, let's rarefy the data at the lowest count per sample. Sometimes you may want to drop samples and choose a higher number. Rarefaction is one of many ways to normalize data across samples. It has been criticized because you end up throwing away reads. McMurdie and Holmes (2014) argued strongly against it, but the method has since held up to scrutiny (e.g., Weiss et al. 2017 Microbiome, Schloss 2024 mSphere).
```{r}
# Rarefy at 949 seqs/sample
set.seed(600) # Set a seed to make this reproducible, although you can also just write to disk and reload the file.
input_filt_rar = single_rarefy(input_filt, 949) # This makes a new mctoolsR dataset called input_filt_rar
# Check seq counts in new dataset
colSums(input_filt_rar$data_loaded) # Good - all 949! It worked.
# Save the file. You can reload it with readRDS().
saveRDS(input_filt_rar, file = "input_filt_rar.rds")
input_filt_rar <- readRDS("input_filt_rar.rds")
# First let's get the number of ASVs (richness) per sample and add it to the mapping file
input_filt_rar$map_loaded$rich <- specnumber(input_filt_rar$data_loaded,
MARGIN = 2)
# Now let's get the Shannon diversity index and add it to the mapping file
# Note: Shannon diversity takes into account the ASV richness, as well as evenness
input_filt_rar$map_loaded$shannon <- diversity(input_filt_rar$data_loaded,
index = "shannon",
MARGIN = 2)
knitr::opts_chunk$set(echo = TRUE)
# R packages required for this tutorial
suppressMessages(library(mctoolsr)) # For inputting, rarefying, filtering, taxonomic analyses
suppressMessages(library(plyr)) # For hulls
suppressMessages(library(tidyverse)) # For data manipulation and plotting
suppressMessages(library(RColorBrewer)) # For color palettes
suppressMessages(library(vegan)) # For alpha and beta diversity analyses
suppressMessages(library(indicspecies)) # For indicator species
suppressMessages(library(car)) # For Levene Test and ANOVA
suppressMessages(library(PMCMRplus)) # For Nemenyi posthoc test
suppressMessages(library(ggh4x)) # For nested facet plots
suppressMessages(library(emmeans)) # For pairwise comparisons
suppressMessages(library(multcomp)) # For automated significant difference letters
suppressMessages(library(zCompositions)) # CLR
suppressMessages(library(compositions)) # Aitchison
suppressMessages(library(reshape2)) # For melting
suppressMessages(library(cowplot)) # For plotting
# Note: This tutorial was run with dplyr 1.1.3. If you are using a newer version of dplyr, you may need to install and load this version using:
#install.packages("dplyr", version='1.1.3')
#library(dplyr)
# If you haven't already installed these packages before, you will need to install them with:
# install.packages()
# For Installing mctoolsR the first time, use:
# install.packages("devtools")
# devtools::install_github("leffj/mctoolsr")
# Custom functions
source("cliffplot_taxa_bars.R")
source("plot_multipatt_asv.R")
# Loading ASV Table
tax_table_fp = system.file('extdata', 'fruits_veggies_taxa_table_wTax.biom',
package = 'mctoolsr')
# Loading mapping file
map_fp = system.file('extdata', 'fruits_veggies_metadata.txt',
package = 'mctoolsr')
# To load YOUR OWN data, replace everything after the "=" with: 'PATH/TO/YOUR_ASV_TABLE_FILE.txt' <- output from dada2 pipeline
# If your files are in your working directly, you do not need to specify the path
# Combine the ASV table and mapping file into an mctoolsR object
input = load_taxa_table(tax_table_fp, map_fp)
# If this has worked correctly, you should get a note saying how many samples have been loaded. For the example dataset, this will say "32 samples loaded".
# Examine the input dataframes.
head(input$data_loaded) # Rows are OTUs, columns are samples
head(input$taxonomy_loaded) # Rows are OTUs (now ASVs), columns are different taxonomic levels
head(input$map_loaded) # Rows are samples, columns are variables
# This is done by getting the column sums of the sequence table, and we'll sort it too.
sort(colSums(input$data_loaded))
# We could also save this as an object and plot it
seqcounts <- as.data.frame(sort(colSums(input$data_loaded)))
# This puts the sample names as row names and the sequence counts column is titled "sort(colSums(input$data_loaded)))
# We'll use the pipeline %>% which is very useful for dataframe management with the dplyr package
# We'll rename the column and make a new column all at once
seqcounts <- as.data.frame(sort(colSums(input$data_loaded))) %>%
rename("seqs" = "sort(colSums(input$data_loaded))") %>%
rownames_to_column(var = "sampleID")
# Now we have a better dataframe with two columns, seqs and sampleID which we can plot
ggplot(seqcounts, aes(reorder(sampleID, seqs, mean), seqs)) + # Dataframe and variables
geom_bar(stat = "identity") + # Type of graph
labs(y = "# Reads", x = "Sample") + # Axes labels
coord_flip() + # Flip axes
theme_classic() + # Plot style. I also use theme_bw() a lot.
theme(axis.text.y = element_text(size = 10)) # Tweak things about text and legend in theme()
# Copy the dataset before doing any filtering
input_filt <- input
# For all filtering steps, taxa removed will be output, make note of this for methods section. Also sometimes it will say "Taxa not found" if it is not found. That is an error and the dataset will not be altered. The search is case sensitive.
# This filters out any ASVs from input dataframe ("input_filt") not assigned to a phylum (at taxonomy level 2 = "NA")
input_filt <- filter_taxa_from_input(input_filt,
at_spec_level = 2,
taxa_to_remove = "unclassified") # 978
# New versions call it NA
#input_filt <- filter_taxa_from_input(input_filt, at_spec_level = 2, taxa_to_remove = "NA")
# Filtering out mitochondria sequences from the filtered input dataset.
input_filt <- filter_taxa_from_input(input_filt,
taxa_to_remove = "f__mitochondria") # 14
# New versions call it Mitochondria
#input_filt <- filter_taxa_from_input(input_filt, taxa_to_remove = "Mitochondria")
# Filtering out chloroplast sequences
input_filt <- filter_taxa_from_input(input_filt,
taxa_to_remove = "c__Chloroplast") # 1
# New versions call it Chloroplast
#input_filt <- filter_taxa_from_input(input_filt, taxa_to_remove = "Chloroplast")
# Filtering out Eukaryotes
#input_filt <- filter_taxa_from_input(input_filt, taxa_to_remove = "Eukaryota") # 0
# If you want to filter out multiple groups at the same time, you can also do that like this:
# input_filt <- filter_taxa_from_input(input_filt,
#                                      taxa_to_remove = c("Chloroplast",
#                                                         "Mitochondria",
#                                                         "Eukaryota"))
# However, it's interesting to do it individually to see how much of each DNA category there was!
# Filtering out singletons and doubletons
# First we'll save the ASV IDs of ASVs with less than 3 total counts
singdoub <- data.frame("count" = rowSums(input_filt$data_loaded)) %>%
filter(count < 3) %>%
mutate(ASV = rownames(.))
# Now we'll provide that list of ASV IDs to the taxa_IDs_to_remove argument
input_filt <- filter_taxa_from_input(input_filt,
taxa_IDs_to_remove = singdoub$ASV)
# NOTE: Each line you run updates the input_filt dataset, so be careful, if something goes wrong go back to the start of filtering.
# NOTE: Databases update and sometimes change how Chloroplast, mitochondria, Eukaryotes are named. If you find that you have not filtered anything, search in the taxa table to make sure that you have the right notation. You can do View(input_filt$taxonomy_loaded) and do a quick search.
# NOTE: You can also use taxa_to_keep, specify the taxonomic level with at_spec_level, remove or keep individual ASVs with taxa_IDs_to_keep or taxa_IDs_to_remove, or filter at an abundance threshold.
# In addition to taxonomic filtering, you can filter out samples. For example, let's filter out lettuce samples. We can give a variable name and levels of the variable to filter or keep.
input_filt <- filter_data(input_filt, # provide input_filt again. careful!
filter_cat = "Sample_type",
filter_vals = "Lettuce") # 28 samples remaining (removed 4)
# Note: normally after you've filtered and rarefied it's recommended to save the dataset as a .rds file. This ensures you use the same dataset and analysis is reproducible (because rarefaction involves random sampling). Then, if you quit your session but want to reanalyze something, you could just start by reading in your .rds files.
# Lets save the filtered but unrarefied dataset.
saveRDS(input_filt, file = "input_filt.rds")
# You can read it in like this:
input_filt <- readRDS("input_filt.rds")
# Let's recheck the reads per sample now that we've filtered out a lot of crap.
sort(colSums(input_filt$data_loaded))
# Rarefy at 949 seqs/sample
set.seed(600) # Set a seed to make this reproducible, although you can also just write to disk and reload the file.
input_filt_rar = single_rarefy(input_filt, 949) # This makes a new mctoolsR dataset called input_filt_rar
# The number of samples remaining is stated. Any samples below the threshold get dropped.
# Check seq counts in new dataset
colSums(input_filt_rar$data_loaded) # Good - all 949! It worked.
# Save the file. You can reload it with readRDS().
saveRDS(input_filt_rar, file = "input_filt_rar.rds")
input_filt_rar <- readRDS("input_filt_rar.rds")
# First let's get the number of ASVs (richness) per sample and add it to the mapping file
input_filt_rar$map_loaded$rich <- specnumber(input_filt_rar$data_loaded,
MARGIN = 2)
# Now let's get the Shannon diversity index and add it to the mapping file
# Note: Shannon diversity takes into account the ASV richness, as well as evenness
input_filt_rar$map_loaded$shannon <- diversity(input_filt_rar$data_loaded,
index = "shannon",
MARGIN = 2)
# Note: since the data_loaded file has ASVs as rows, MARGIN must be set to 2.
# Two categories example
leveneTest(input_filt_rar$map_loaded$rich ~ input_filt_rar$map_loaded$Farm_type)
# Variance homogeneous (p > 0.05)
shapiro.test(input_filt_rar$map_loaded$rich)
# Richness normally distributed (p > 0.05)
t.test(input_filt_rar$map_loaded$rich ~ input_filt_rar$map_loaded$Farm_type)
# No significant difference in richness among the two categories
# If Levene's Test or Shapiro-Wilk Test p < 0.05, use Wilcoxon Test
wilcox.test(input_filt_rar$map_loaded$rich ~ input_filt_rar$map_loaded$Farm_type)
# Same result
# Box and whisker plot with points
ggplot(input_filt_rar$map_loaded, aes(Farm_type, rich, colour = Farm_type)) +
geom_boxplot(outlier.shape = NA) +
geom_point(size = 3, alpha = 0.5) +
labs(x = "Farm Type", y = "ASV Richness", colour = "Farm Type") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14))
# Box and whisker plot with jittered points (geom_jitter instead of geom_point)
ggplot(input_filt_rar$map_loaded, aes(Farm_type, rich, colour = Farm_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
labs(x = "Farm Type", y = "ASV Richness", colour = "Farm Type") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14))
# Don't need legend because each category is already clearly labeled
ggplot(input_filt_rar$map_loaded, aes(Farm_type, rich, colour = Farm_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
labs(x = "Farm Type", y = "ASV Richness", colour = "Farm Type") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
legend.position = "none")
# Change colors to be colorblind friendly (e.g., red and blue is better than red and green)
ggplot(input_filt_rar$map_loaded, aes(Farm_type, rich, colour = Farm_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
labs(x = "Farm Type", y = "ASV Richness", colour = "Farm Type") +
scale_colour_manual(values = c("red", "blue")) +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
legend.position = "none")
# Save plot. This specifies a size and makes it reproducible. pdf default dimensions are in inches. could also use png or jpeg or ggsave. The file will go into working directory unless you specify a different path.
pdf(file = "FarmType.pdf", width = 4, height = 4)
ggplot(input_filt_rar$map_loaded, aes(Farm_type, rich, colour = Farm_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
labs(x = "Farm Type", y = "ASV Richness", colour = "Farm Type") +
scale_colour_manual(values = c("red", "blue")) +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
legend.position = "none")
dev.off()
# Now let's plot Shannon diversity. I cut and pasted the above plot and changed the y input and axis label
ggplot(input_filt_rar$map_loaded, aes(Farm_type, shannon, colour = Farm_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
labs(x = "Farm Type", y = "Shannon diversity", colour = "Farm Type") +
scale_colour_manual(values = c("red", "blue")) +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
legend.position = "none")
# Three category example
leveneTest(input_filt_rar$map_loaded$rich ~ input_filt_rar$map_loaded$Sample_type)
# Variance homogeneous (p > 0.05)
m <- aov(input_filt_rar$map_loaded$rich ~ input_filt_rar$map_loaded$Sample_type)
shapiro.test(m$residuals)
# Residuals normally distributed (p > 0.05)
# Note: Here we test the assumption that the residuals (not the data itself) are normally distributed
# Other diagnostics - learn more here (https://data.library.virginia.edu/diagnostic-plots/)
# Note: R markdown will plot all 4 diagnostic plots. If not in R markdown, click in the console and hit Return to see each diagnostic plot.
plot(m)
# Check the model results.
summary(m)
# Significant effect. Run posthoc test to see which groups are different from each other.
# Mushrooms different from spinach and strawberries. No diff between spinach and strawberries
TukeyHSD(m)
# If Levene's Test or Shapiro-Wilk Test p < 0.05, use Krukal-Wallis Test
# Note: The Nemenyi test only accepts a factor independent variable so we add as.factor() to the independent variable.
kruskal.test(input_filt_rar$map_loaded$rich ~ input_filt_rar$map_loaded$Sample_type)
# Significant effect. (agrees with ANOVA). Run posthoc.
kwAllPairsNemenyiTest(input_filt_rar$map_loaded$rich ~ as.factor(input_filt_rar$map_loaded$Sample_type))
# Similar result, but spinach/mushroom different now only marginal.
# Use ANOVA result if assumptions passed because there is more power and data aren't rank transformed, which is a loss of information.
# Plot. Just copy the previous plot, change the variable name and the colour argument!
# Here we'll try the viridis palette.
ggplot(input_filt_rar$map_loaded, aes(Sample_type, rich, colour = Sample_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
labs(x = "Sample Type", y = "ASV Richness", colour = "Farm Type") +
scale_colour_viridis_d() +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
legend.position = "none")
# Now, since there was a significant difference, let's add some letter text. We'll make a new dataframe containing coordinates for the letters. Groups with different letters are significantly different. So it should be a b b. We set y to 180 to be above the maximum ASV richness.
label_df <- data.frame(x = c("Mushrooms", "Spinach", "Strawberries"),
y = c(180, 180, 180),
label = c("a", "b", "b"))
# Plot with added geom_text
ggplot(input_filt_rar$map_loaded, aes(Sample_type, rich, colour = Sample_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
geom_text(data = label_df, aes(x, y, label = label), size = 5, inherit.aes = F) +
labs(x = "Sample Type", y = "ASV Richness", colour = "Farm Type") +
scale_colour_viridis_d() +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
legend.position = "none")
## Stats for rich and Shannon using ANOVA and emmeans and cld.
m1 <- aov(rich ~ Sample_type, data = input_filt_rar$map_loaded)
t1 <- emmeans(object = m1, specs = "Sample_type") %>%
cld(object = ., adjust = "Tukey", Letters = letters, alpha = 0.05) %>%
mutate(name = "rich",
y = 180)
m2 <- aov(shannon ~ Sample_type, data = input_filt_rar$map_loaded)
t2 <- emmeans(object = m2, specs = "Sample_type") %>%
cld(object = ., adjust = "Tukey", Letters = letters, alpha = 0.05) %>%
mutate(name = "shannon",
y = 5)
# Note: The sidak note is fine. It's still a Tukey posthoc test, just with sidak adjustment.
# Combine the labels
label_df <- rbind(t1, t2)
# Set names for the facet strips
facet_df <- c("rich" = "(a) Richness",
"shannon" = "(b) Shannon")
# Make the data long format
alpha_long <- input_filt_rar$map_loaded %>%
pivot_longer(cols = c("rich", "shannon"))
# This will put the richness and Shannon values into a column named "value"
# It will make a new column ("name") which maps the values to either richness or shannon
# Plot using facet_wrap to make the two panels. We use scales = "free_y" to let the y-axis scale vary among the two panels.
ggplot(alpha_long, aes(Sample_type, value, colour = Sample_type)) +
geom_boxplot(outlier.shape = NA) +
geom_jitter(size = 3, alpha = 0.5) +
geom_text(data = label_df,
aes(Sample_type, y, label = str_trim(.group)),
size = 5, inherit.aes = F) +
labs(x = "Sample Type", y = "ASV Richness", colour = "Farm Type") +
scale_colour_viridis_d() +
facet_wrap(~name, ncol = 2, scales = "free_y", labeller = as_labeller(facet_df)) +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14),
strip.text = element_text(size = 18),
legend.position = "none")
# Calculate dissimilarity matrix
dm <- calc_dm(input_filt_rar$data_loaded)
# NOTE: calc_dm uses Bray-Curtis by default. Can change to others using method=type_of_function in the script
# Let's calculate an ordination from the distance matrix
ord <- calc_ordination(dm, 'nmds')
# NOTE: You can also run pcoa and others by changing the code above from NMDS
# Now plot the ordination using the default mctoolsR function.
plot_ordination(input_filt_rar, ord, 'Sample_type', 'Farm_type', hulls = TRUE)
#this is a nice thing to do at the start of an analysis to see what your data is doing
# NOTE: plot_ordination is a good way to quickly plot data. However, if you want to do more complicated edits to a plot, you should save the ordination values from the calc_ordination() step as a dataframe and plot in ggplot as shown below.
# Bray-Curtis dissimilarity matrix. Note: By default the data are square-root transformed.
bc <- calc_dm(input_filt_rar$data_loaded)
# Principle Coordinates Analysis (PCoA)
pcoa <- cmdscale(bc, k = nrow(input_filt_rar$map_loaded) - 1, eig = T)
# Variation Explained
eigenvals(pcoa)/sum(eigenvals(pcoa)) # 23.3, 16.6 % variation explained
# Make axis labels with % variation explained rounded to 1 digit.
pcoaA1 <- paste("PC1: ", round((eigenvals(pcoa)/sum(eigenvals(pcoa)))[1]*100, 1), "%")
pcoaA2 <- paste("PC2: ", round((eigenvals(pcoa)/sum(eigenvals(pcoa)))[2]*100, 1), "%")
# Save Axis 1 and 2 scores to the mapping file
input_filt_rar$map_loaded$Axis01 <- scores(pcoa)[,1]
input_filt_rar$map_loaded$Axis02 <- scores(pcoa)[,2]
# Function for making a convex hull
find_hull <- function(df) df[chull(df$Axis01, df$Axis02),]
# Calculate hulls and save to dataframe
micro.hulls <- ddply(input_filt_rar$map_loaded, c("Sample_type", "Farm_type"), find_hull)
# Plot
ggplot(input_filt_rar$map_loaded, aes(Axis01, Axis02, colour = Sample_type, shape = Farm_type)) +
geom_polygon(data = micro.hulls, aes(colour = Sample_type, fill = Sample_type),
alpha = 0.1, show.legend = F) +
geom_point(size = 2, alpha = 0.5) +
labs(x = pcoaA1,
y = pcoaA2,
colour = "Food",
shape = "Farm") +
scale_colour_viridis_d() +
scale_fill_viridis_d() +
theme_bw() +
theme(legend.position = "right",
axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14))
# First perform zero replacement and center log ratio (CLR) transformation. Use filtered but unrarefied data for this ("input_filt").
otu_czm <- cmultRepl(t(input_filt$data_loaded), label = 0, method = "CZM")
otu_clr <- clr(otu_czm)
aclr <- compositions::dist(otu_clr)
# Filter dropped samples
# Columns and rows containing more than 80% zeros/unobserved values were deleted
# This is the bad thing about this method. We have now lost some samples and ASVs.
# You can also avoid this by adjusting the z.warning.
# Here we just proceed with the default.
dim(t(input_filt$data_loaded)) # 28 samples, 933 ASVs
dim(otu_czm) # 23 samples, 144 ASVs
# Make a sampleID column
input_filt$map_loaded$sampleID <- rownames(input_filt$map_loaded)
# Filter out sampleIDs not in the CLR dataset. Save as new mctoolsR object.
input_filt_clr <- filter_data(input_filt,
filter_cat = "sampleID",
keep_vals = rownames(otu_czm))
# PCA (principle components analysis)
d.pcx <- prcomp(aclr)
# % variation explained
d.mvar <- sum(d.pcx$sdev^2)
# Make axes labels with % variation explained
PC1 <- paste("PC1: ", round((sum(d.pcx$sdev[1]^2)/d.mvar)*100, 1), "%")
PC2 <- paste("PC2: ", round((sum(d.pcx$sdev[2]^2)/d.mvar)*100, 1), "%")
# Save scores to map_loaded dataframe
input_filt_clr$map_loaded$Axis01 <- d.pcx$x[,1]
input_filt_clr$map_loaded$Axis02 <- d.pcx$x[,2]
# Transform the scores
input_filt_clr$map_loaded$Axis01 <- input_filt_clr$map_loaded$Axis01/sqrt(sum((input_filt_clr$map_loaded$Axis01 - mean(input_filt_clr$map_loaded$Axis01))^2))
input_filt_clr$map_loaded$Axis02 <- input_filt_clr$map_loaded$Axis02/sqrt(sum((input_filt_clr$map_loaded$Axis02 - mean(input_filt_clr$map_loaded$Axis02))^2))
# Calculate hulls
micro.hulls <- ddply(input_filt_clr$map_loaded, c("Sample_type", "Farm_type"), find_hull)
# Plot
ggplot(input_filt_clr$map_loaded, aes(Axis01, Axis02, colour = Sample_type, shape = Farm_type)) +
geom_polygon(data = micro.hulls, aes(colour = Sample_type, fill = Sample_type),
alpha = 0.1, show.legend = F) +
geom_point(size = 2, alpha = 0.5) +
labs(x = PC1,
y = PC1,
colour = "Food",
shape = "Farm") +
scale_colour_viridis_d() +
scale_fill_viridis_d() +
theme_bw() +
theme(legend.position = "right",
axis.title = element_text(face = "bold", size = 16),
axis.text = element_text(size = 14))
# Note: This is very consistent with the Bray-Curtis and PCoA.
calc_pairwise_permanovas(bc, input_filt_rar$map_loaded, "Sample_type")
# What about pairwise PERMANOVA? This is similar to a Tukey posthoc an an ANOVA.
# Grouping variable must be a factor
input_filt_rar$map_loaded$Sample_type <- as.factor(input_filt_rar$map_loaded$Sample_type)
set.seed(1223)
calc_pairwise_permanovas(bc, input_filt_rar$map_loaded, "Sample_type")
m <- adonis(bc ~ input_filt_rar$map_loaded$Sample_type*input_filt_rar$map_loaded$Farm_type)
m
rm(m)
m <- adonis(bc ~ input_filt_rar$map_loaded$Sample_type*input_filt_rar$map_loaded$Farm_type)
m
summary(m)
m$aov.tab
m_pw <- calc_pairwise_permanovas(bc, input_filt_rar$map_loaded, "Sample_type")
m_pw
m_pw
View(m_pw)
class(m_pw)
m_pw
m_pw$X1
View(m_pw)
m_pw # Each group is significantly different from the other.
library(mctoolsr)
version(mctoolsr)
library(mctoolsr, version)
